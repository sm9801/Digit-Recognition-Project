# Digit-Recognition-Project

For this project, we will experiment with classifying images into the correct digit using linear and logistic regression, non-linear features, regularization, and kernel tricks. We work with the MNIST database, which contains binary images of handwritten digits commonly used to train image processing systems. The data was collected from among Census Bureau employees and high school students, and contains 60000 training digits and 10000 testing digits. All of them have been normalized and centered in a fixed image size of 28 by 28 pixels. 

First, a linear regression model was implemented and tested by calculating its error. Unfortunately, the error was large, no matter how the lambda parameter was changed. Then, a One vs Rest Support Vector Machine (SVM) and Multiclass SVM algorithms were implemented and tested, both giving much smaller errors than the linear regression model. Lastly, we implemented a multinomial regression (softmax) model and gradient descent algorithm; this model gave similar errors as the SVM models. However, by experimenting with the temperature parameter of the multinomial regression model, we were able to reduce the error. 

Afterwards, we approached the problem differently, by classifying the digits by their (mod 3) value, such that the new label is the old label modulo 3. After we implemented this step, we trained the multinomial regression model with the data with the new labels. With this method, we got lower errors than the mutinomial model trained with the original data. 

Now, we experimented with changing the representation of the training data. We needed to represent each image using different features in place of the raw pixel values. Subsequently, we would investigate how well our regression models performs when fed different representations of the data. To do this, we implemented a principle component analysis algorithm for dimensional reduction. By projecting the training data onto 18 principle components, we created a new representation of the data. When modelled with the multinomial regression model from before, we had a slightly higher error. 
